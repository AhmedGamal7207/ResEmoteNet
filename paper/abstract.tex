\begin{abstract}
    Deep convolutional neural networks (DCNNs) have been the state-of-the-art in many applications, including computer vision and tasks like Facial Emotion Recognition (FER). Nevertheless, recent studies indicate that DCNNs often struggle to maintain context as they increase in depth, reducing their practicality in real-world situations. In this paper, we introduce FER FourforAll, which leverages layer activations and gradient-weighted class activation mapping (Grad-CAM) to enhance understandability. FER FourforAll is designed to classify six fundamental facial emotions and has been rigorously tested against leading state-of-the-art methods. Empirical results indicate that FER FourforAll achieves superior accuracy on two established FER benchmarks, as well as on our own aggregated FER dataset. Additionally, the model's effectiveness is demonstrated through real-world image and video examples, including real-time live camera streams. These results highlight the capabilities of FER FourforAll as a reliable and understandable option for live facial emotion detection.
\end{abstract}