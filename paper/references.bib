@article{divyashree2022stress,
  title={Stress and anxiety detection through speech recognition using deep neural network},
  author={Divyashree, P and Yadav, A Ghanavi and Jayadev, Namratha and Chidaravalli, S},
  journal={International Journal of Innovative Research in Technology},
  volume={8},
  number={11},
  pages={5},
  year={2022}
}

@article{le2024patt,
  title={PAtt-Lite: lightweight patch and attention MobileNet for challenging facial expression recognition},
  author={Le Ngwe, Jia and Lim, Kian Ming and Lee, Chin Poo and Ong, Thian Song and Alqahtani, Ali},
  journal={IEEE Access},
  year={2024},
  publisher={IEEE}
}

@article{hosseini2023multimodal,
  title={Multimodal Stress Detection Using Facial Landmarks and Biometric Signals},
  author={Hosseini, Majid and Bodaghi, Morteza and Bhupatiraju, Ravi Teja and Maida, Anthony and Gottumukkala, Raju},
  journal={arXiv preprint arXiv:2311.03606},
  year={2023}
}

@article{siddiqui2020multimodal,
  title={A multimodal facial emotion recognition framework through the fusion of speech with visible and infrared images},
  author={Siddiqui, Mohammad Faridul Haque and Javaid, Ahmad Y},
  journal={Multimodal Technologies and Interaction},
  volume={4},
  number={3},
  pages={46},
  year={2020},
  publisher={MDPI}
}

@article{zhang2023dual,
  title={A Dual-Direction Attention Mixed Feature Network for Facial Expression Recognition},
  author={Zhang, Saining and Zhang, Yuhang and Zhang, Ye and Wang, Yufei and Song, Zhigang},
  journal={Electronics},
  volume={12},
  number={17},
  pages={3595},
  year={2023},
  publisher={MDPI}
}

@article{zhang2022real,
  title={Real-time mental stress detection using multimodality expressions with a deep learning framework},
  author={Zhang, Jing and Yin, Hang and Zhang, Jiayu and Yang, Gang and Qin, Jing and He, Ling},
  journal={Frontiers in Neuroscience},
  volume={16},
  pages={947168},
  year={2022},
  publisher={Frontiers Media SA}
}

@inproceedings{deng2020retinaface,
  title={Retinaface: Single-shot multi-level face localisation in the wild},
  author={Deng, Jiankang and Guo, Jia and Ververas, Evangelos and Kotsia, Irene and Zafeiriou, Stefanos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5203--5212},
  year={2020}
}

@inproceedings{liliana2019emotion,
  title={Emotion recognition from facial expression using deep convolutional neural network},
  author={Liliana, Dewi Yanti},
  booktitle={Journal of physics: conference series},
  volume={1193},
  pages={012004},
  year={2019},
  organization={IOP Publishing}
}

@article{minaee2021deep,
  title={Deep-emotion: Facial expression recognition using attentional convolutional network},
  author={Minaee, Shervin and Minaei, Mehdi and Abdolrashidi, Amirali},
  journal={Sensors},
  volume={21},
  number={9},
  pages={3046},
  year={2021},
  publisher={mdpi}
}

@article{wen2023distract,
  title={Distract your attention: Multi-head cross attention network for facial expression recognition},
  author={Wen, Zhengyao and Lin, Wenzhong and Wang, Tao and Xu, Ge},
  journal={Biomimetics},
  volume={8},
  number={2},
  pages={199},
  year={2023},
  publisher={MDPI}
}

@article{mehendale2020facial,
  title={Facial emotion recognition using convolutional neural networks (FERC)},
  author={Mehendale, Ninad},
  journal={SN Applied Sciences},
  volume={2},
  number={3},
  pages={446},
  year={2020},
  publisher={Springer}
}

@article{ma2021facial,
  title={Facial expression recognition with visual transformers and attentional selective fusion},
  author={Ma, Fuyan and Sun, Bin and Li, Shutao},
  journal={IEEE Transactions on Affective Computing},
  volume={14},
  number={2},
  pages={1236--1248},
  year={2021},
  publisher={IEEE}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

% CK+ Dataset
@inproceedings{lucey2010extended,
  title={The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression},
  author={Lucey, Patrick and Cohn, Jeffrey F and Kanade, Takeo and Saragih, Jason and Ambadar, Zara and Matthews, Iain},
  booktitle={2010 ieee computer society conference on computer vision and pattern recognition-workshops},
  pages={94--101},
  year={2010},
  organization={IEEE}
}

% RAF-DB Dataset
@inproceedings{li2017reliable,
  title={Reliable crowdsourcing and deep locality-preserving learning for expression recognition in the wild},
  author={Li, Shan and Deng, Weihong and Du, JunPing},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2852--2861},
  year={2017}
}

% FER2013 Dataset
@inproceedings{goodfellow2013challenges,
  title={Challenges in representation learning: A report on three machine learning contests},
  author={Goodfellow, Ian J and Erhan, Dumitru and Carrier, Pierre Luc and Courville, Aaron and Mirza, Mehdi and Hamner, Ben and Cukierski, Will and Tang, Yichuan and Thaler, David and Lee, Dong-Hyun and others},
  booktitle={Neural Information Processing: 20th International Conference, ICONIP 2013, Daegu, Korea, November 3-7, 2013. Proceedings, Part III 20},
  pages={117--124},
  year={2013},
  organization={Springer}
}

@inproceedings{barsoum2016training,
  title={Training deep networks for facial expression recognition with crowd-sourced label distribution},
  author={Barsoum, Emad and Zhang, Cha and Ferrer, Cristian Canton and Zhang, Zhengyou},
  booktitle={Proceedings of the 18th ACM international conference on multimodal interaction},
  pages={279--283},
  year={2016}
}

% AffectNet Dataset
@article{mollahosseini2017affectnet,
  title={Affectnet: A database for facial expression, valence, and arousal computing in the wild},
  author={Mollahosseini, Ali and Hasani, Behzad and Mahoor, Mohammad H},
  journal={IEEE Transactions on Affective Computing},
  volume={10},
  number={1},
  pages={18--31},
  year={2017},
  publisher={IEEE}
}

% Evaluation Metrics Book
@article{dalianis2018evaluation,
  title={Evaluation metrics and evaluation},
  author={Dalianis, Hercules and Dalianis, Hercules},
  journal={Clinical Text Mining: secondary use of electronic patient records},
  pages={45--53},
  year={2018},
  publisher={Springer}
}

@misc{Olugbenga2024,
  author = {Michael Olugbenga},
  title = {Balanced Accuracy: When Should You Use It?},
  year = {2024},
  howpublished = {Neptune.ai blog},
  url = {https://neptune.ai/blog/balanced-accuracy},
  note = {Accessed: 2024-05-22}
}
