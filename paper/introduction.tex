\section{Introduction}
Facial Emotion Recognition (FER) is a field of artificial intelligence that focuses on identifying human emotions from facial expressions using image processing and machine learning techniques. This technology plays a crucial role in enhancing human-computer interaction by providing systems the ability to interpret and respond to user emotions, mirroring human empathy. FER is used in various fields such as enhancing security systems by identifying suspicious behaviors in public areas, and analyzing consumer reactions in marketing research to enhance customer experiences. It is crucial in automotive safety for monitoring driver alertness and in healthcare \cite{8535710}, \cite{onyema2021enhancement}, \cite{info11030128} for assessing patient wellbeing and managing pain.

FER is more challenging than general image classification because of the intricate and nuanced nature of human expressions. While conventional image classification identifies individual, usually static objects in images, FER examines diverse and constantly changing expressions among individuals and cultures, acknowledging wide variations in emotions. Challenges in this task include low resolution, changing lighting, obstructed views (like glasses or facial hair), and brief emotional micro-expressions. Moreover, due to the subjective nature of emotions, there is ambiguity in FER as a single facial expression can convey different emotions in various contexts. This variability can hold back the learning capabilities of a solution, since the model might face difficulties in generalizing across various topics, ultimately resulting in decreased accuracy and dependability. For example, the differences between an angry and disgusted face may be little, yet the variances between two persons within the same emotion class can be rather considerable.

Advances in FER models have been greatly influenced by the necessity to tackle the difficulties presented by in-the-wild datasets. These databases usually contain a wide range of environments and scenarios from the real world, making it difficult to accurately recognize facial expressions. One challenge has been the lack of negative expressions in these databases, mainly because they are rare and short in natural environments. This lack of balance results in models that have a lower ability to identify negative emotions, which are important for applications needing subtle emotional comprehension.
There has been a change in focus towards using bigger, more intricate neural network structures to improve accuracy and dependability. Deep learning models, especially those that make use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs), have been leading the way in this transition. These networks can capture spatial features and temporal dynamics of facial expressions, which improves their ability to accurately classify emotions in different real-world scenarios. However, as the depth increases, these models frequently lose sight of the context of the data.
The latest advancements in FER technology not only improve the performance of models in various challenging conditions but also broaden the scope of FER applications in sectors like security, healthcare, customer service, and interactive entertainment.

In this paper, FER FourforAll, a network built on top of CNN is proposed to improve the performance of FER. First, a simple CNN block is employed as a backbone model. A Squeeze and Excitation block is added to the backbone model to enforce the model to extract significant features to classify facial expressions accurately. Further addition of Residual Networks \cite{he2016deep} makes the model extract even more features. Multiple fully connected layers are added to classify better and increase the performance of the model.
Finally, to evaluate the performance of the proposed method, five datasets i.e., CK+, RAF-DB, FER2013, FERPlus and AffectNet are employed as the benchmark datasets of this research.

The main contributions of this work are as follows:
\begin{enumerate}
	\item We collect, preprocess, and evaluate the training and testing data from various public databases thoroughly.
	\item We implement all classification models from scratch and optimize them with several techniques in a systematic manner. Meanwhile, we illustrate the classification scores with the confusion matrix heat map.
	\item We provide qualitative benefits such as interpretability to explain our model with gradient-weighted class activation mapping and face landmarks.
\end{enumerate}
